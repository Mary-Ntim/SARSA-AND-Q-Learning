# ğŸ§  GridWorld RL Assignment: SARSA vs. Q-learning

This repository contains the full implementation and analysis of SARSA and Q-learning algorithms applied to a 5x5 GridWorld navigation task. The goal is to compare how both agents learn optimal policies using Îµ-greedy action selection and evaluate their performance through trajectory plots and episode reward trends.

---

## ğŸ“Œ Task Summary

- **Environment**: 5x5 GridWorld
- **Start state**: 21 (bottom-left)
- **Terminal states**: 1 and 5 (top-left and top-right)
- **Penalty zones**: States 16, 17, 19, 20 â†’ âˆ’20 reward and reset to start
- **Regular move**: âˆ’1 reward per step
- **Goal**: Learn the optimal path to a terminal while minimizing penalties

The agent uses **Îµ-greedy exploration** and learns with both:
- **SARSA** (on-policy)
- **Q-learning** (off-policy)

---

## ğŸ—‚ï¸ Repository Structure

```bash
.
â”œâ”€â”€ gridworld.py             # Environment definition
â”œâ”€â”€ sarsa.py                 # SARSA training and evaluation
â”œâ”€â”€ q_learning.py            # Q-learning training and evaluation
â”œâ”€â”€ plot_trajectory.py       # Grid and trajectory plot generator
â”œâ”€â”€ reward_plot.py           # Reward trend visualization
â”œâ”€â”€ README.md                # This file
â””â”€â”€ results/
    â”œâ”€â”€ sarsa_trajectory.png
    â”œâ”€â”€ q_learning_trajectory.png
    â””â”€â”€ reward_plot.png

pip install numpy matplotlib

